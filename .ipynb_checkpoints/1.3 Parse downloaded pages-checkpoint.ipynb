{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import csv \n",
    "import re\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open(\"homework1.txt\", \"r\") #aprire il proprio file .txt degli URLs\n",
    "l=f1.readlines()\n",
    "data = ['bookTitle', 'bookSeries', 'bookAuthors', 'ratingValue',\"ratingCount\",\"reviewCount\",\"Plot\",\"NumberofPages\",\"Publishing Date\",\"Characters\",\"Setting\",\"Url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cambiare path con il proprio!!!\n",
    "\n",
    "for i in range(2): #al posto di 2 va messo len(l)\n",
    "    with open(\"C:/Users/Flavia/Desktop/cartella/folder-\"+str(i+1)+\"/article_\"+str(i+1)+\".html\", 'rb') as html:  #cambiare path!!!\n",
    "        soup = BeautifulSoup(html,\"html.parser\")\n",
    "    lista=[]\n",
    "    #title\n",
    "    try:\n",
    "        lista.append(soup.find('h1').text.strip())\n",
    "    except:\n",
    "        lista.append('')\n",
    "        \n",
    "    #bookseries\n",
    "    try:\n",
    "        lista.append(soup.find('h2',id='bookSeries').text.strip())\n",
    "    except:\n",
    "        lista.append('')\n",
    "        \n",
    "    #author name\n",
    "    try:\n",
    "        lista.append(soup.find('a',class_='authorName').text.strip())\n",
    "    except:\n",
    "        lista.append('')\n",
    "        \n",
    "    #rating value\n",
    "    try:\n",
    "        lista.append(soup.find('span',itemprop='ratingValue').text.strip())\n",
    "    except:\n",
    "        lista.append('')\n",
    "        \n",
    "    #ratingCount\n",
    "    try:\n",
    "        lista.append(soup.find_all('a',class_='gr-hyperlink',href='#other_reviews')[0].text.strip().replace('\\r', '').replace('\\n', ''))\n",
    "    except:\n",
    "        lista.append('')\n",
    "        \n",
    "    #reviewCount\n",
    "    try:\n",
    "        lista.append(soup.find_all('a',class_='gr-hyperlink',href='#other_reviews')[1].text.strip().replace('\\r', '').replace('\\n', ''))\n",
    "    except:\n",
    "        lista.append('')\n",
    "    \n",
    "    #plot\n",
    "    try:\n",
    "        plott=soup.find('div',id='description').contents[1].text.strip()+soup.find('div',id='description').contents[3].text.strip()\n",
    "        if detect(plott)=='en':\n",
    "            lista.append(plott)\n",
    "        else:\n",
    "            lista.append('')\n",
    "    except:\n",
    "        lista.append('')\n",
    "        \n",
    "    #number of pages\n",
    "    try:\n",
    "        lista.append(soup.find('span', itemprop='numberOfPages').text.strip())\n",
    "    except:\n",
    "        lista.append('')\n",
    "        \n",
    "    #Publishing Date\n",
    "    try:\n",
    "        a=soup.find_all('div', class_='row')[1].text\n",
    "        match_obj = re.split('Published', re.split('by', a)[0])[1]\n",
    "        lista.append(match_obj.strip())\n",
    "    except:\n",
    "        lista.append('')\n",
    "        \n",
    "    #characters\n",
    "    try:\n",
    "        lista.append(soup.find_all('div',class_=\"infoBoxRowItem\")[4].text.strip().replace('...more','').replace('...less',''))\n",
    "    except:\n",
    "        lista.append('')\n",
    "        \n",
    "    #setting\n",
    "    try:\n",
    "        lista.append(soup.find_all('div',class_=\"infoBoxRowItem\")[5].text.strip().replace('\\n','').replace('\\r',''))\n",
    "    except:\n",
    "        lista.append('')\n",
    "        \n",
    "    #URL\n",
    "    lista.append(l[i].strip())\n",
    "    \n",
    "    path=\"C:/Users/Flavia/Desktop/cartella/folder-\"+str(i+1)+'/article_'+str(i+1)+'.tsv'        #cambiare path!!!!!!\n",
    "    with open(path, 'w', newline='') as f_output:\n",
    "        tsv_output = csv.writer(f_output, delimiter='\\t')\n",
    "        tsv_output.writerow(data)\n",
    "        tsv_output.writerow(lista)\n",
    "        f_output.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
